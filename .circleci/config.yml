#version: 2.1
# Use a package of configuration called an orb.
#orbs:
#  create_infrastructure:
     # docker:
    #    - image: amazon/aws-cli
   #  steps: 
  #    - checkout
#      - run:
      #      name: Create CloudFormation Stack
     #       command: |
    #          aws cloudformation deploy \
   #             --template-file template.yml \
  #              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
 #               --region us-east-1   
# Sequential workflow
#workflows:
#  myWorkflow:
#    jobs:
#      - create_infrastructure

version: 2.1

jobs: 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
        # Use $OldBucketID environment variable or mybucket644752792305 below.
        # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-over
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 

  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
 # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
##  smoke_test:
##    docker:
##      - image: alpine:latest
##    steps:
 ##     - run: apk add --update curl
  ##    - run:
   ##       name: smoke test
    ##      command: |
     ##       URL="https://blog.udacity.com/"
      ##      if curl -s --head ${URL} 
       ##     then
        #3      return 0
        ##    else
      ##        return 1
        ##    fi

  #config_infra:
   # docker:
    #  - image: python:3.7-alpine3.11
    #steps: 
     # - checkout
     # - add_ssh_keys:
      #    fingerprints: ["ff:36:ea:ad:ae:f0:27:84:c1:45:fb:f6:bb:6d:3e:e9"]
      #- run:
       ###     apk add --update ansible
      #- run: 
      #    name: Configure Server
       #   command: |
        #    ansible-playbook -i inventory.txt main.yml
            

workflows:
  myWorkflow:
    jobs:
        - create_and_deploy_front_end
        - promote_to_production:
            requires: 
              - create_and_deploy_front_end
        - get_last_deployment_id
        - clean_up_old_front_end:
            requires:
              - get_last_deployment_id
              - promote_to_production






